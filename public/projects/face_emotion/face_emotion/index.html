<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Emotion Classification Based on Face Images</title>
<meta name="description" content="Describe your website">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" href="../../../css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="../../../css/font-awesome.min.css">
<link rel="stylesheet" href="../../../css/owl.carousel.css">
<link rel="stylesheet" href="../../../css/owl.theme.css">
<link rel="stylesheet" href="../../../css/github-gist.css">
<script src="../../../js/highlight.pack.js"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>


  <link href="../../../css/style.default.css" rel="stylesheet" id="theme-stylesheet">


<link href="../../../css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="../../../img/favicon.png">


</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              
<div id="sidebar" class="col-sb-fixedpos col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="../../../">Wenyu Li</a></h1>

    <ul class="sidebar-menu">
      
      
        <li><a href="../../../">Home</a></li>
      
        <li><a href="../../../about/">About</a></li>
      
        <li><a href="../../../projects/">Projects</a></li>
      
        <li><a href="../../../contact/">Get in touch</a></li>
      

       

<div class="panel panel-default sidebar-menu">

   

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" results="0" class="form-control" placeholder="Search">
                <input type="hidden" name="q" value="site:/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>



 

      

 

      
 

    </ul>
    <p class="social">
  
  
  
  
  
  <a href="mailto:wyuli@ucdavis.edu" data-animate-hover="pulse" class="email">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://www.linkedin.com/in/wenyu-li/" data-animate-hover="pulse">
    <i class="fa fa-linkedin"></i>
  </a>
  
  
  
<a href="https://github.com/liwy1113">
  <i class="fa fa-github"></i>
</a>

</p>


    <div class="copyright">
      <p class="credit">
        
          &copy;2017 Wenyu Li
        
        | Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>
</div>

<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background col-main-fixedpos">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="../../../">Wenyu Li</a></h1>
</div>


            <div class="row">
                  <div class="col-sm-4">
                    <div class="image">
                      <img src="../../../projects/face_emotion/faceimage.png" class="img-responsive" alt="">
                    </div>
                  </div>

                  <div class="col-md-8">
                      <h2>Emotion Classification Based on Face Images</h2>
                          <p class="author-category">
                            Wenyu Li
                          </p>

                          <p class="date-comments">
                          <i class="fa fa-calendar-o"></i> June 6, 2016
                          </p>

                          <ul class="tags-cloud">
                          
                          </ul>
                   
                            

                          
                  
                      </div>
                    </div>
                  </br>

<div class="row">
   <div class="content-column-content">
          <div class="col-lg-8">

<link href="../../../rmarkdown-libs/font-awesome/css/font-awesome.min.css" rel="stylesheet" />

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#clustering">Clustering</a>
<ul>
<li><a href="#clustering-for-one-person’s-emotion">Clustering for one person’s emotion</a></li>
<li><a href="#clustering-for-two-people’s-emotion">Clustering for two people’s emotion</a></li>
</ul></li>
<li><a href="#supervised-machine-learning">Supervised Machine Learning</a>
<ul>
<li><a href="#dimensional-reduction">Dimensional Reduction</a></li>
<li><a href="#model-selection">Model Selection</a></li>
<li><a href="#pooling-and-prediction">Pooling and Prediction</a></li>
</ul></li>
<li><a href="#conclusion-and-discussion">Conclusion and Discussion</a></li>
<li><a href="#references">References</a></li>
</ul>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>People usually have different facial expressions according to their emotions. Human can easily recognize the emotions on people’s face. Here we want to achieve the goal of emotion recognition on face images based on machine. We used a subset of the <a href="http://www.consortium.ri.cmu.edu/ckagree/">Cohn-Kanade dataset</a>, with 610 images with 640*400 pixels in total. Each image has a label with six levels of emotions: 0=neutral, 1=anger, 2=disgust, 3=happy, 4=sadness and 5=surprise. We would like to explore the Unsu- pervised Machine Learning methods to distinguish the different emotions given a set of different emotional im- ages of one or two people. Furthermore, apply some Supervised Machine Learning methods to recognize precisely its corresponding emotion given a new image. In order to classify the images well, we convert all of images to grayscale, detect the face, and crop them to only keep the faces as a pre-processing procedure.</p>
</div>
<div id="clustering" class="section level2">
<h2>Clustering</h2>
<div id="clustering-for-one-persons-emotion" class="section level3">
<h3>Clustering for one person’s emotion</h3>
<p>We have used different linkage methods in agglomerative hierarchical procedures, like average linkage, com- plete linkage, single linkage methods, etc. We could easily find that, in average, linkage method, the results of clustering are reasonable, because each clustering can represent one emotion. There are 4 kinds of emotions: surprise, sadness, neutral, and happy. We found that different linkage methods show the same clustering results.</p>
<p>Moreover, K-means method and K-medoids meth- ods also show the same clustering result, and the number K of clusters is determined by mean of silhouette value.</p>
<p>The silhouette ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. From the plot above, we could easily find that K = 4 is the best choice. When we perform clustering analysis on another person’s face images, the clustering results is also good. There are also 4 kinds of emotions: happy, fear, neutral, contempt.</p>
</div>
<div id="clustering-for-two-peoples-emotion" class="section level3">
<h3>Clustering for two people’s emotion</h3>
<p>Then we try to perform clustering analysis based on two person’s face images. We find that clustering method could also perform a good result.</p>
<p>Each cluster still represents one kind of emotion of one person. However, when we add lots of different people’s face image, the feature of each clusters would become no obvious.</p>
</div>
</div>
<div id="supervised-machine-learning" class="section level2">
<h2>Supervised Machine Learning</h2>
<div id="dimensional-reduction" class="section level3">
<h3>Dimensional Reduction</h3>
<p>Since the 3-dimensions 610$<span class="math inline">\(350\)</span><span class="math inline">\(350 data cannot be used on fitting the classification models, the dimen- sional reduction is necessary here. The steps are as following: Considering we have 610 face images with 350\)</span>times<span class="math inline">\(350 pixels. We can view each image as 350\)</span>times$350, which is 122500 dimensions data and denote it as <span class="math inline">\(p\)</span>. We have 610 face images, denote it as n and so our original face data matrix can be denoted <span class="math inline">\(X_{n×p}\)</span>. Transforming the data to Y=<span class="math inline">\(\frac{1}{\sqrt{n-1}}(X-1\mu&#39;)\)</span>, where <span class="math inline">\(\mu&#39;= \frac{1}{n}1&#39;X\)</span>. Since the sample covariance matrix <span class="math inline">\(Y&#39;Y\)</span> has 122500$$122500 dimensions, we cannot directly compute eigenvalues and eigenvectors of it. Based on the knowledge of SVD and PCA[3], the eigenvectors of <span class="math inline">\(Y&#39;Y\)</span> is <span class="math inline">\(\phi = Y&#39;u\)</span>, where u is the eigenvectors of <span class="math inline">\(YY&#39;\)</span>. (Usually, we have to normalize <span class="math inline">\(\phi\)</span>). Select m = 100 principle components, which denotes as <span class="math inline">\(\Phi_m=(\phi_1,...,\phi_m)\)</span>. Then for each face image x, the score of its component is <span class="math inline">\(\hat{Y}_{m\times 1}=\Phi_m&#39;(x-\mu)\)</span> Therefore, <span class="math inline">\(\hat{x}=\Phi_m\hat{Y}+\mu\)</span>. Since m <span class="math inline">\(&lt;\)</span> (n,p), we can project our data onto a lower dimension space. Then we could use it for recognition of face images.</p>
</div>
<div id="model-selection" class="section level3">
<h3>Model Selection</h3>
<p>To get the prediction of labels based on different face images, we decide to apply different models and choose the models with the best prediction ability. Since the sample sizes under each emotion are different (from label 0 to 5, the sample sizes are respectively 327, 45, 59, 69, 25, 81), we used stratified random sampling to split our dataset into two parts: train set (80%) and test set (20%). We fit eight different models and tuned the parameters with a 5-fold stratified cross validation on the training set: linear SVM (tuned C and gamma), radial basis function kernel SVM (tuned C and gamma), 3-degree polynomial SVM (tuned C and gamma), logistic regression (tuned C), K Nearest Neighbors (tuned K), Naive Bayes, Random Forest tree (tuned the number of trees in the forest) and linear discriminant analysis. Then we got the average of the error rates from the 5 fold CV for each of these models.</p>
<p>The following table shows the result of the chosen parameters which can obtain the smallest cross valida- tion error rate.</p>
<pre><code>                    Model      |     Error
              ---------------- | -------------
                Linear SVM     |     0.166
                 Rbf SVM       |     0.217
                 Poly SVM      |     0.463
           Logistic Regression |     0.143
                   KNN         |     0.438
                Naive Bayes    |     0.296
                   RFT         |     0.336
                   LDA         |     0.174</code></pre>
<p>From the table, we can see the linear SVM (C = 0.01) and logistic regression (C = 0.1) algorithm have the best predictive ability among these different methods, since they have the smallest cross validation error rate. To get a better prediction, we do a pooling process by constructing an ensemble learning on these two best methods. The detailed analysis is in the following part.</p>
</div>
<div id="pooling-and-prediction" class="section level3">
<h3>Pooling and Prediction</h3>
<p>Pooling method is a general approach to combine the information from different sources and probability distributions[2]. Based on the linear SVM (C = 0.01) and logistic regression (C = 0.1), We’d like to ensemble them in order to balance out their individual weak- nesses and obtain a better prediction because they are almost equally well performing when training the data. Then the aggregate probability is <span class="math display">\[P(y_i|c_j) = \sum_{k = 1}^k\alpha_kP(y_i|c_j)\]</span></p>
<p>where K is the number of models (Here K = 2). <span class="math inline">\(P(y_i|c_j)\)</span> means the predicted probability assigned by the model K to the response <span class="math inline">\(y_i\)</span> occurring in the multiclass <span class="math inline">\(c_j\)</span>. <span class="math inline">\(\alpha_k\)</span> is the weights: <span class="math display">\[\alpha_k = log\frac{1-error_k}{error_k}\]</span></p>
<p>Then normalized <span class="math inline">\(\alpha_k\)</span> to sum to one and plug into the following functions. Since it is a multiclass problem with 6 labels in total, we used One-Vs-One method by constructing one classifier per pair of classes during the procedure of getting the final probability. After constructing the new pooled model, we obtained the normalized weights <span class="math inline">\(\alpha_{linear svm} = 0.475\)</span> and <span class="math inline">\(\alpha_{logistic} = 0.525\)</span> by using the errors obtaining from the training set. Then we applied the pooling model, the linear SVM (C = 0.01) and the logistic regression (C = 0.1) on the new data from the 20% test dataset. Compare the results of the pooling model and the results of those two models:</p>
<pre><code>             |   Pooling    | linear SVM  |  logistic
-------------|--------------|-------------|-------------
  Accuracy   |    0.861     |    0.844    |   0.836</code></pre>
<p>Therefore, the pooling method has a higher predicted accuracy score and obviously improves the performance.</p>
</div>
</div>
<div id="conclusion-and-discussion" class="section level2">
<h2>Conclusion and Discussion</h2>
<p>The following is the table of accuracy score on each labels using pooling model and the best two models.</p>
<pre><code>                |   Pooling  | linear SVM |  logistic
   -------------|------------|------------|-------------
     neutral    |    0.95    |    1.00    |    0.94
      anger     |    0.56    |    0.44    |    0.44
     disgust    |    0.75    |    0.75    |    0.75
      happy     |    0.86    |    0.86    |    0.93
     sadness    |    0.50    |    0.17    |    0.33
     surprise   |    0.88    |    0.75    |    0.81</code></pre>
<p>By this table,we can find that the emotions of anger and sadness usually have higher probability to be misclassified. Neutral and Happy are more likely to be classified correctly. Then we plotted the confusion matrix to evaluate the quality of the output of the classifier, obtained from the pooling model results.</p>
<p>From this plot, we can find anger emotions are easily classified as neutral emotions while sadness emotions can be classified as anger with relatively high probability. It might because of the face changing between anger and neutral is somewhat not so obvious. Basically, the difference is usually on the mouth movement. Happy with teeth showing and surprise with an O shape mouth will make these two emotions easily classified.</p>
<p>In a word, emotion recognition is very complex and hard, even for human eyes. In different context, the similar emotions can usually be interpreted as different meaning depending on the environment. Besides, the images we used were all taken at the front and very clear. The real world data won’t be as good as this data. Further study needed to be conducted on the images which were not at the front nor clear, by using, such as, some feature descriptors procedure.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ul>
<li><a href="http://www.consortium.ri.cmu.edu/ckagree/">Cohn-Kanade dataset</a></li>
<li><a href="https://en.wikipedia.org/wiki/Silhouette_(clustering)">Silhouette Value</a></li>
<li><a href="http://scikit-learn.org/">Sk-learn packages</a></li>
</ul>
</div>

      
       </div>
     </div>
   </div>





        <a href="#" class="back-to-top">
        <i class="fa fa-arrow-circle-o-up" aria-hidden="true"></i>

        </a>

         <div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = '';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </div>
   

          </div>
      </div>
  </div>
  <script src="../../../js/jquery.min.js"></script>
<script src="../../../js/bootstrap.min.js"></script>
<script src="../../../js/jquery.cookie.js"> </script>
<script src="../../../js/ekko-lightbox.js"></script>
<script src="../../../js/jquery.scrollTo.min.js"></script>
<script src="../../../js/masonry.pkgd.min.js"></script>
<script src="../../../js/imagesloaded.pkgd.min.js"></script>
<script src="../../../js/owl.carousel.min.js"></script>
<script src="../../../js/front.js"></script>
<script src="../../../js/backtotop.js"></script> 

</body>
</html>
